这篇论文的核心贡献在于提出了一种名为 **MobileNets** 的**轻量级、高效的卷积神经网络架构**，旨在满足移动和嵌入式视觉应用对低延迟、小模型尺寸的需求。

该论文的主要创新点体现在其网络结构设计上：

1. **深度可分离卷积 (Depthwise Separable Convolutions)**：
    
    MobileNets 的核心构建块是深度可分离卷积。这种卷积将标准卷积分解为两个独立的层：一个深度卷积 (depthwise convolution)，对每个输入通道应用单一滤波器进行空间滤波；以及一个 $1\times1$ 的逐点卷积 (pointwise convolution)，用于组合深度卷积的输出特征。这种分解极大地减少了计算量和模型参数量，相比标准卷积可节省约8-9倍的计算资源，同时仅带来微小的精度损失。
    
1. **模型缩减超参数 (Model Shrinking Hyperparameters)**：
    
    论文引入了两个简单的全局超参数，用于在延迟（计算量）和精度之间进行有效权衡：
    
    - **宽度乘数 (Width Multiplier) $\alpha$**：通过均匀地减少每一层的通道数（输入通道变为 $\alpha M$，输出通道变为 $\alpha N$）来“瘦身”网络。这能以大约 $\alpha^2$ 的比例二次方地减少计算量和参数量。
        
    - **分辨率乘数 (Resolution Multiplier) $\rho$**：通过降低输入图像的分辨率，并相应地按比例缩减每一层的特征图分辨率来实现。这能以 $\rho^2$ 的比例减少计算量。
        

虽然 MobileNets 本身是通用的视觉模型架构，但其高效的设计使其可以作为**骨干网络 (backbone)** 被集成到各种下游任务中，**包括（但不限于）瑕疵检测系统**，特别是在需要实时处理或部署在资源受限设备上的工业场景中。该论文通过在 ImageNet 分类、COCO 目标检测、人脸属性识别等多个基准任务上的实验，证明了 MobileNets 在保持有竞争力的精度的同时，显著降低了计算复杂度和模型尺寸。