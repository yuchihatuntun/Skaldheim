### 绪论

### 前置知识

### 滤波器与卷积核

#### 图像直方图

##### 图像的本质：像素矩阵

一张数字图像，尤其是我们这里讨论的**灰度图**，可以被理解为一个二维矩阵。 矩阵中的每一个元素都代表一个像素，其数值被称为像素值或灰度值，表示该点的亮度。 通常，这个值用一个字节（8位）来表示，范围从0到255，其中0代表最暗的黑色，255代表最亮的白色。

##### 什么是图像直方图

图像直方图是一种图形化的表示方法，它显示了一张图像中亮度（灰度）值的分布频率，即统计从0到255的每一个灰度级在这张图像中总共出现了多少次。

<span style="background:rgba(252, 163, 180, 0.55)">将二维的像素空间变换为一维的统计分布</span>。  这让我们能从一个宏观的、统计学的角度来理解图像的整体色调分布。

##### 应用实例

###### 辅助目标检测，减少误报

在目标检测任务中，算法可能会将一些背景区域误判为目标（例如，将一块纹理复杂的背景识别为人脸）。 此时，直方图可以提供一个有效的<span style="background:rgba(252, 163, 180, 0.55)">判别依据</span>。

###### 辅助医疗诊断

#### 图像变换函数

我们将研究如何主动地**修改**这些像素值，从而创造出一张新的图像。

> [!note] 函数定义
> 一个图像可以被定义为一个函数 $f$。这个函数的作用是将一个二维的像素坐标 $(x, y)$ 映射到一个灰度值。

> [!note] 数学表达
> 对于一个矩形图像，这个函数关系可以写成  
> $$
> f:[a,b]\times[c,d]\to[0,255]
> $$
> 其中 $[a,b]\times[c,d]$ 表示图像的坐标范围（宽度和高度），$[0,255]$ 是函数输出的范围，代表可能的灰度值。

**彩色图像**：这个概念同样适用，只是函数的输出不再是一个单一的数值，而是一个包含红 (R)、绿 (G)、蓝 (B) 三个通道值的向量：
$$
f(x, y) =
\begin{bmatrix}
r(x, y) \\
g(x, y) \\
b(x, y)
\end{bmatrix}
$$

**直方图本身就是图像变换函数的一种**。它将整个二维坐标空间 $(x,y)$ 的信息变换（或说聚合）成了一个一维的统计分布。

##### 变换操作：对函数进行运算

###### 对像素值进行运算

例如：

$$g(x,y)=f(x,y)+20$$  

这个操作会遍历每一个坐标 $(x,y)$，读取原始像素值 $f(x,y)$，然后将其增加20，得到新图像的像素值。这种操作会使整张图片变亮。这类只依赖当前点像素值的变换，我们称之为**点操作**。更多点操作的例子，如通过 $255-x$ 实现颜色翻转，或通过 $x\cdot2$ 来增强对比度。

###### 对坐标进行运算

例如：  
$$g(x,y)=f(-x,y)$$  
这个操作在计算新图像 $(x,y)$ 位置的像素值时，会去采样原始图像 $(-x,y)$ 位置的像素值。其最终效果是将图像**水平翻转**。

如果我们想让新像素值不仅与当前点有关，**还受到其周围邻近像素的影响**，应该怎么做呢？

#### 图像滤波

##### 什么是图像滤波，为何需要它

> [!note] 图像滤波定义
> 图像滤波是生成新图像的过程，其中每个新像素的值由原始图像对应位置及其局部邻域的像素值共同决定。也就是说，计算新图像某一点时，需要参考该点及其周围的一小块区域的像素信息。

> [!note] 目的
> 我们进行滤波是为了从图像中提取有用信息或增强图像，包括：
> - **增强与美化**：去除噪声、平滑或锐化图像，使其更清晰。
> - **特征提取**：提取物体的边缘或轮廓，为后续形状识别提供基础。

##### 核心机制：卷积核 (Kernel) 与卷积 (Convolution)


### 边缘检测

### Course 10 注意力和Transformers

> [!tip] 前置问题
> 1. 从NLP跨界到CV的里程碑工作是什么？
> 2. BERT、GPT-3、T5这些模型都是什么机制？
> 3. 这两种注意力机制有什么共同点和差异？

#### 注意力(空间特征 v.s. 注意力)

### 生成模型

> [!tip] 前置问题
> 1. 自编码器（AE）是什么？AE和变分自编码器（VAE）有什么区别？
> 2. GAN的灵感来源是什么？
> 3. 生成式模型与判别式模型的区别是什么？

#### PixelCNN

##### 完全可见置信网络 (Fully Visible Belief Networks, FVBN)

> [!quote] FVBN的概率分解机制
> FVBN 将 $n$ 维观测变量 $\mathbf{x} = (x_1, x_2, \ldots, x_n)$ 的联合概率 $p(\mathbf{x})$ 分解为一系列条件概率的乘积：
>
> $$
> p(\mathbf{x}) = \prod_{i=1}^{n} p(x_i \mid x_1, x_2, \ldots, x_{i-1})
> $$
>
> 其中，每个条件概率 $p(x_i \mid x_{<i})$ 表示当前变量 $x_i$ 对之前所有变量 $x_1$ 到 $x_{i-1}$ 的依赖关系。这种分解方式基于概率图模型中的完全有向图结构，所有节点（变量）之间均存在显式的依赖连接。
>
> 即**按照固定的顺序一块一块地拼图，而且每一步都要计算下一块拼图该怎么放**。

其属于**显式密度建模 (Explicit Density Modeling)** 的范畴，

> [!tip] 定义
> 显式密度建模是指通过数学形式显式地定义概率密度函数 $p_{\text{model}}(x; \theta)$，其中 $\theta$ 为模型参数。该密度函数能够直接计算观测数据 $x$ 的似然值，并通过最大化似然估计（MLE）或贝叶斯推断等方法优化参数，使得模型分布 $p_{\text{model}}$ 尽可能接近真实数据分布 $p_{\text{data}}$。

$$p(x) = p(x_1, x_2, \ldots, x_n)$$

