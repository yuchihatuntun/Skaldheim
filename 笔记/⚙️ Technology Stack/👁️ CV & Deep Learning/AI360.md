### 绪论

### 前置知识

### 滤波器与卷积核

#### 图像直方图

##### 图像的本质：像素矩阵

一张数字图像，尤其是我们这里讨论的**灰度图**，可以被理解为一个二维矩阵。 矩阵中的每一个元素都代表一个像素，其数值被称为像素值或灰度值，表示该点的亮度。 通常，这个值用一个字节（8位）来表示，范围从0到255，其中0代表最暗的黑色，255代表最亮的白色。

##### 什么是图像直方图

图像直方图是一种图形化的表示方法，它显示了一张图像中亮度（灰度）值的分布频率，即统计从0到255的每一个灰度级在这张图像中总共出现了多少次。

<span style="background:rgba(252, 163, 180, 0.55)">将二维的像素空间变换为一维的统计分布</span>。  这让我们能从一个宏观的、统计学的角度来理解图像的整体色调分布。

##### 应用实例

###### 辅助目标检测，减少误报

在目标检测任务中，算法可能会将一些背景区域误判为目标（例如，将一块纹理复杂的背景识别为人脸）。 此时，直方图可以提供一个有效的<span style="background:rgba(252, 163, 180, 0.55)">判别依据</span>。

###### 辅助医疗诊断

#### 图像变换函数

我们将研究如何主动地**修改**这些像素值，从而创造出一张新的图像。

> [!note] 函数定义
> 一个图像可以被定义为一个函数 $f$。这个函数的作用是将一个二维的像素坐标 $(x, y)$ 映射到一个灰度值。

> [!note] 数学表达
> 对于一个矩形图像，这个函数关系可以写成  
> $$
> f:[a,b]\times[c,d]\to[0,255]
> $$
> 其中 $[a,b]\times[c,d]$ 表示图像的坐标范围（宽度和高度），$[0,255]$ 是函数输出的范围，代表可能的灰度值。

**彩色图像**：这个概念同样适用，只是函数的输出不再是一个单一的数值，而是一个包含红 (R)、绿 (G)、蓝 (B) 三个通道值的向量：
$$
f(x, y) =
\begin{bmatrix}
r(x, y) \\
g(x, y) \\
b(x, y)
\end{bmatrix}
$$

**直方图本身就是图像变换函数的一种**。它将整个二维坐标空间 $(x,y)$ 的信息变换（或说聚合）成了一个一维的统计分布。

##### 变换操作：对函数进行运算

###### 对像素值进行运算

例如：

$$g(x,y)=f(x,y)+20$$  

这个操作会遍历每一个坐标 $(x,y)$，读取原始像素值 $f(x,y)$，然后将其增加20，得到新图像的像素值。这种操作会使整张图片变亮。这类只依赖当前点像素值的变换，我们称之为**点操作**。更多点操作的例子，如通过 $255-x$ 实现颜色翻转，或通过 $x\cdot2$ 来增强对比度。

###### 对坐标进行运算

例如：  
$$g(x,y)=f(-x,y)$$  
这个操作在计算新图像 $(x,y)$ 位置的像素值时，会去采样原始图像 $(-x,y)$ 位置的像素值。其最终效果是将图像**水平翻转**。

如果我们想让新像素值不仅与当前点有关，**还受到其周围邻近像素的影响**，应该怎么做呢？

#### 图像滤波

##### 什么是图像滤波，为何需要它

> [!note] 图像滤波定义
> 图像滤波是生成新图像的过程，其中每个新像素的值由原始图像对应位置及其局部邻域的像素值共同决定。也就是说，计算新图像某一点时，需要参考该点及其周围的一小块区域的像素信息。

> [!note] 目的
> 我们进行滤波是为了从图像中提取有用信息或增强图像，包括：
> - **增强与美化**：去除噪声、平滑或锐化图像，使其更清晰。
> - **特征提取**：提取物体的边缘或轮廓，为后续形状识别提供基础。

##### 核心机制：卷积核 (Kernel) 与卷积 (Convolution)


### 边缘检测

### Course 10 注意力和Transformers

> [!tip] 前置问题
> 1. 从NLP跨界到CV的里程碑工作是什么？
> 2. BERT、GPT-3、T5这些模型都是什么机制？
> 3. 这两种注意力机制有什么共同点和差异？

#### 注意力(空间特征 v.s. 注意力)

### 生成模型

> [!tip] 前置问题
> 1. 自编码器（AE）是什么？AE和变分自编码器（VAE）有什么区别？
> 2. GAN的灵感来源是什么？
> 3. 生成式模型与判别式模型的区别是什么？

#### PixelCNN

##### 完全可见置信网络 (Fully Visible Belief Networks, FVBN)

> [!note] FVBN的概率分解机制
> FVBN 将 $n$ 维观测变量 $\mathbf{x} = (x_1, x_2, \ldots, x_n)$ 的联合概率 $p(\mathbf{x})$ 分解为一系列条件概率的乘积：
>
> $$
> p(\mathbf{x}) = \prod_{i=1}^{n} p(x_i \mid x_1, x_2, \ldots, x_{i-1})
> $$
>
> 其中，每个条件概率 $p(x_i \mid x_{<i})$ 表示当前变量 $x_i$ 对之前所有变量 $x_1$ 到 $x_{i-1}$ 的依赖关系。这种分解方式基于概率图模型中的完全有向图结构，所有节点（变量）之间均存在显式的依赖连接。
>
> 即**按照固定的顺序一块一块地拼图，而且每一步都要计算下一块拼图该怎么放**。

其属于**显式密度建模 (Explicit Density Modeling)** 的范畴，

> [!note] 定义
> 显式密度建模是指通过数学形式显式地定义概率密度函数 $p_{\text{model}}(x; \theta)$，其中 $\theta$ 为模型参数。该密度函数能够直接计算观测数据 $x$ 的似然值，并通过最大化似然估计（MLE）或贝叶斯推断等方法优化参数，使得模型分布 $p_{\text{model}}$ 尽可能接近真实数据分布 $p_{\text{data}}$。

$$p(x) = p(x_1, x_2, \ldots, x_n)$$

其中，图像`x`被视为一个`n`维的随机向量，`x₁`到`xₙ`是它的各个分量，即图像中的每一个像素。

因此，$p(x)$就是所有`n`个像素的**联合概率分布**。该模型的挑战在于，图像像素之间存在着复杂的空间依赖关系，导致这个联合分布的<span style="background:rgba(252, 163, 180, 0.55)">维度极高</span>且<span style="background:rgba(252, 163, 180, 0.55)">结构复杂</span>。

但是一口气计算这个联合分布概率实在是困难，我们不一口气画完整张图，而是**一个像素一个像素地画**。就像写文章时一个词一个词地写，即通过 **链式法则 (Chain Rule)** 实现对显式概率密度的建模

分解后的形式为：

$$
p(x) = \prod_{i=1}^{n} p(x_i \mid x_1, \ldots, x_{i-1})
$$

这个公式将一个难以处理的高维联合概率，精确地转换为了`n`个一维条件概率的乘积 。

![alt text](image-2.png)

###### 自回归建模 (Autoregressive Modeling)

> [!note] 定义
> 给定一个 $D$ 维随机变量 $\mathbf{x} = (x_1, x_2, \ldots, x_D)$，其联合概率分布 $p(\mathbf{x})$ 被分解为：
> $$
> p(\mathbf{x}) = \prod_{i=1}^{D} p(x_i \mid x_1, x_2, \ldots, x_{i-1})
> $$
> 其中 $p(x_i \mid x_{<i})$ 表示变量 $x_i$ 在给定所有前序变量 $x_1, \ldots, x_{i-1}$ 下的条件概率。  
> 这种分解方式称为**自回归分解（Autoregressive Decomposition）**，因为每个变量“回归”于其前面的变量。

- 该分解具有**自回归**的性质：第 $i$ 个像素 $x_i$ 的概率分布，只依赖于它之前的所有像素 $x_1$ 至 $x_{i-1}$ 。这为生成过程定义了一个明确的、有序的依赖关系和计算顺序，如图所示，从左上角第一个像素 $x_1$ 开始，依次生成直到最后一个像素 $x_n$ 。

- 每一个条件概率 $p(x_i \mid x_1, \ldots, x_{i-1})$ 都是一个一维的概率分布，其**参数由之前的像素值（即条件）所决定**。

###### 参数化与优化 (Parameterization and Optimization):

- **参数化**：像素值之间的条件依赖关系极其复杂，无法用简单的函数来描述。因此，我们使用神经网络来对这些条件概率分布进行参数化。神经网络的强大拟合能力使其可以学习从条件（$x_1$ 到 $x_{i-1}$）到目标像素 $x_i$ 分布的复杂映射。

- **优化**：模型的训练目标是**最大化训练数据的对数似然 (Maximize Log-Likelihood)**。通过在整个训练集上最大化 $\log p(\mathbf{x})$，模型被驱动去学习能够最好地解释观测数据的参数，从而捕获真实数据的内在分布。

##### PixelCNN

> [!note] 定义
> 给定一张图像 $\mathbf{x}$（尺寸为 $n \times n \times C$，其中 $C$ 为通道数，如 RGB 图像的 $C = 3$），PixelCNN 将联合概率 $p(\mathbf{x})$ 分解为序列条件概率的乘积：
> $$
> p(\mathbf{x}) = \prod_{i=1}^{n^2} p(x_i \mid x_1, x_2, \ldots, x_{i-1})
> $$
> 其中：
> - $x_i$ 表示按光栅扫描顺序（左上到右下）排列的第 $i$ 个像素；
> - 每个 $p(x_i \mid x_{<i})$ 是给定前序像素时当前像素的条件概率，通过神经网络建模。
>
> 对于 RGB 图像，条件概率进一步分解为通道间的依赖关系：
> $$
> p(x_i \mid x_{<i}) = p(x_{i,R} \mid x_{<i}) \cdot p(x_{i,G} \mid x_{<i}, x_{i,R}) \cdot p(x_{i,B} \mid x_{<i}, x_{i,R}, x_{i,G})
> $$
> 即 R 通道仅依赖前序像素，G 通道额外依赖当前像素的 R 值，B 通道依赖 R 和 G 值。

###### 核心机制：带掩码的卷积 (Masked Convolution)

- 与前一页提出的基于链式法则的自回归思想一致，PixelCNN 旨在对每个像素 $x_i$ 的条件概率分布 $p(x_i \mid x_{<i})$ 进行建模。
- 它创新性地使用**卷积神经网络 (CNN)** 来捕获这种条件依赖性。为保证自回归特性——即模型在预测 $x_i$ 时只能利用其上下文 (causal context)，即已经生成的像素——PixelCNN采用了一种特殊的**带掩码的卷积 (Masked Convolution)**。
- 这种掩码将卷积核中对应于当前及<span style="background:rgba(252, 163, 180, 0.55)">未来像素位置的权重置为零</span>，从而确保了信息流的单向性，严格遵守了概率的有序分解。

###### 与PixelRNN的对比与优势

- PixelRNN使用循环神经网络（RNN）来建模像素间的序列依赖关系，其计算是严格串行的。
- PixelCNN利用卷积操作，可以在**训练阶段**并行计算所有像素位置的条件分布。这是因为训练时整张图像是已知的，卷积可以在整个图像上一次性完成。这使得其训练效率远高于PixelRNN。

###### 主要局限性：串行生成过程 (Sequential Generation)

- 尽管训练过程可以并行化，但其**生成（采样）过程**仍然是严格串行的。
- 为了生成一个新样本，模型必须从 $x_1$ 开始，依次生成 $x_2$，$x_3$，… 直至 $x_n$。每生成一个像素，都需要将之前所有生成的像素作为输入，进行一次完整的前向传播。
- 因此，生成一张 $N \times N$ 的图像需要进行 $N^2$ 次网络前向传播。例如，对于一张32x32的图像，这需要1024次前向传播，导致其生成速度极其缓慢，这是该方法在实际应用中的一个主要瓶颈。

##### <span style="font-weight:bold; color:rgb(255, 177, 10)">优点 (Advantages)</span>

1. **可计算的精确似然 (Tractable Exact Likelihood)**：PixelCNN 作为一个显式密度模型，其最主要的优势是能够为任意给定图像 $x$ 计算出精确的似然值 $p(x)$ 。这不仅为模型的性能评估提供了量化指标，也使其适用于异常检测等需要精确概率值的任务。

2. **稳定的优化过程 (Stable Optimization)**：该模型的目标函数是最大化对数似然，这是一个定义良好且稳定的优化目标。相比于GAN等需要处理对抗性博弈的模型，PixelCNN的训练过程通常更加直接和收敛。

3. **可观的样本质量 (Decent Sample Quality)**：PixelCNN 能够生成质量尚可的样本，在早期的生成模型中具有很强的竞争力。

##### 性能提升方法 (Performance Enhancement Methods):

为了克服原生PixelCNN的局限性并提升其生成样本的质量，后续研究提出了一系列改进措施：

- **门控卷积层 (Gated Convolutional Layers)**：引入门控机制（如Gated PixelCNN），为网络增加了乘性的非线性交互，使其能学习更复杂的像素依赖关系。

> [!note] 数学原理
> - **核心思想**：通过乘性非线性交互增强模型表达能力。
> - **双路卷积计算**：输入特征图 $x$ 经过卷积层，生成两倍通道数的输出：
>   $$
>   \text{combined} = W * x
>   $$
> - **门控分离**：将输出沿通道维度拆分为门控信号和特征信号：
>   $$
>   \text{gate}, \text{feature} = \text{chunk}(\text{combined}, 2, \text{dim} = 1)
>   $$
> - **动态特征调制**：门控信号经 sigmoid 激活生成权重，与特征信号逐元素相乘：
>   $$
>   h = \sigma(\text{gate}) \odot \text{feature}
>   $$
> - **梯度流动分析**：反向传播时，梯度可通过两条路径传播，有效缓解梯度消失问题：
>   $$
>   \frac{\partial h}{\partial x} = \sigma'(\text{gate}) \odot \text{feature} + \sigma(\text{gate}) \odot W_f
>   $$

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class GatedPixelCNNBlock(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):
        super().__init__()
        # 门控卷积层
        self.conv = nn.Conv2d(in_channels, 2 * out_channels, 
                             kernel_size=kernel_size, 
                             padding=padding)
        
        # 垂直堆叠的掩码卷积（保持因果性）
        self.mask_conv = nn.Conv2d(out_channels, 2 * out_channels,
                                  kernel_size=kernel_size,
                                  padding=padding)
        
        # 初始化门控卷积权重
        nn.init.kaiming_normal_(self.conv.weight)
        nn.init.zeros_(self.conv.bias)

    def forward(self, x):
        # 标准门控卷积
        total_features = self.conv(x)
        gate, features = torch.chunk(total_features, 2, dim=1)
        gated_features = torch.sigmoid(gate) * features
        
        # 添加掩码卷积路径
        masked = self.mask_conv(gated_features)
        gate_m, feat_m = torch.chunk(masked, 2, dim=1)
        
        # 残差连接
        return x + (torch.sigmoid(gate_m) * feat_m)
```

- **快速连接 (Short-cut connections)**：采用类似ResNet的残差或跳跃连接，以缓解深度网络中的梯度消失问题，使模型能够构建得更深，从而学习更长距离的依赖。

> [!note] ResNet（残差网络）
> ResNet（Residual Network）由微软研究院的 Kaiming He 等人在 2015 年提出，是一种深度卷积神经网络架构。其核心创新在于通过**残差学习**和**跳跃连接（Skip Connection）**，有效解决了深层网络训练中的梯度消失和网络退化问题，使得训练超过 100 层的超深网络成为可能。
>
> - **传统网络的局限性**：深层网络容易出现梯度消失或网络退化（层数增加后准确率反而下降），因为多层非线性变换难以直接拟合恒等映射（Identity Mapping）。
> - **残差块的引入**：ResNet 将目标映射 $H(x)$ 分解为 $H(x) = F(x) + x$，其中 $x$ 是输入（通过跳跃连接直接传递），$F(x)$ 是残差函数，由卷积层学习输入与输出之间的差异（残差）。
> - **优势**：学习残差比直接学习原始映射更容易，尤其当 $H(x) \approx x$ 时，残差 $F(x)$ 趋近于 0，网络可通过跳跃连接保留原始信息。

- **离散化的逻辑损失 (Discretized Logistic Loss)**：相较于标准的Softmax损失，使用混合离散逻辑分布作为损失函数能更好地对像素值的连续性进行建模，从而提升生成样本的视觉质量。
- **多尺度建模 (Multi-scale Modeling)**：通过多尺度架构，让模型在不同分辨率上捕获图像的全局结构和局部细节，有效扩展了模型的感受野和建模能力。
- **训练技巧 (Training Tricks)**：包括但不限于学习率调度、数据增强、优化器选择等一系列在实践中被证明有效的训练策略。

#### 变分自编码器（VAE）

