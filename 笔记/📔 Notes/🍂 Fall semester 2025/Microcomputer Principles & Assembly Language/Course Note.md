### 课程目标与成绩要求

#### 课程目标

- <span style="background:rgba(163, 218, 252, 0.55)">微型计算机（Intel x86）的基本工作原理及系统</span>，Intel x86是广泛使用的计算机架构，了解其基本工作原理有助于理解计算机如何执行指令、处理数据等核心运作机制。
- <span style="background:rgba(163, 218, 252, 0.55)">处理器体系结构</span>，处理器是计算机的核心部件，学习其体系结构能知晓处理器的内部构造、指令集等，明白它如何高效地进行计算和控制。
- <span style="background:rgba(163, 218, 252, 0.55)">软件及汇编语言程序设计</span>，汇编语言是一种接近机器语言的编程语言，学习它有助于深入理解计算机软件与硬件的交互，能让学习者从底层层面去设计和编写程序，为后续的软件开发等工作奠定基础。

#### 课程资料与成绩组成

|材料类别|具体内容|
| ---- | ---- |
|主要教学内容|上课ppt，上传到中山大学在线教学平台<https://lms.sysu.edu.cn/my/index.php>|
|教材|《微机原理、汇编语言与接口技术》，周杰英、张萍、郭雪梅、黄方军编著，人民邮电出版社|
|辅助材料| - 《计算机组成与设计：硬件/软件接口（原书第5版·ARM版）》，戴维·A.帕特森（David A.Patterson）、约翰·L.亨尼斯著，陈微译，机械工业出版社出版，第1版，2018年9月<br> - Randal E. Bryant and David R. O'Hallaron, *Computer Systems: A Programmer’s Perspective*, Third Edition (CS:APP3e), Pearson, 2016.|

|成绩类型|占比|具体说明|
| ---- | ---- | ---- |
|平时成绩|40%|包括作业和考勤|
|期末成绩|60%|考试方式为闭卷，成绩评定采用百分制|

### 绪论outline

> [!note]
> **什么是嵌入式系统，和其他系统有什么区别**
>
> 嵌入式系统是**以应用为中心、以计算机技术为基础**，软硬件可裁剪（根据需求定制），能满足设备对功能、可靠性、成本、体积、功耗严格要求的**专用计算机系统**。它并非独立设备，而是“嵌入”到其他设备（如家电、汽车、工业机械）中的核心控制单元，本质是为特定场景提供精准控制或数据处理能力。
>
> **嵌入式系统的核心构成**
>
> - **硬件层**：以微处理器（MPU）、微控制器（MCU，如STM32、51单片机）、片上系统（SoC）为核心，搭配专用外设（如传感器、执行器、通信模块）和最小化电路（电源、时钟、存储），资源高度精简（通常内存几KB~几GB、存储几MB~几百GB）。
> - **软件层**：以“专用固件”为核心，通常包含实时操作系统（RTOS，如FreeRTOS、uC/OS）或无操作系统（裸机程序），软件功能单一且固化（多存储在ROM/Flash中，而非可随意安装卸载），专注于完成特定任务（如“控制电机转速”“采集温度数据”）。
> - **典型应用场景**：汽车电子（发动机ECU、中控屏）、智能家居（冰箱温控、扫地机器人）、工业控制（PLC控制器、传感器节点）、消费电子（智能手环、路由器）、医疗设备（血糖仪、心电监测仪）等。
>
> **嵌入式系统与其他系统的核心区别**
>
> 嵌入式系统的核心特征是“**专用化**”，而通用计算机、服务器等系统的核心特征是“**通用化**”。以下通过对比表格，清晰区分嵌入式系统与两类常见系统的差异：
>
> | 对比维度                | 嵌入式系统                                  | 通用计算机系统（PC/笔记本）                | 服务器系统（数据中心服务器）                |
> |-------------------------|---------------------------------------------|-------------------------------------------|---------------------------------------------|
> | **设计目标**            | 满足特定设备的单一/少数功能（如“控制汽车刹车”“监测心率”），强调**实时性、可靠性、低功耗** | 满足多场景通用需求（办公、娱乐、编程），强调**灵活性、多任务处理** | 满足大规模数据处理/服务提供（云计算、数据库），强调**高吞吐量、高并发、稳定性** |
> | **软硬件架构**          | 软硬件高度定制化，硬件资源精简（按需裁剪），软件多为“裸机程序/轻量RTOS”，功能固化 | 硬件标准化（CPU、内存、硬盘可灵活升级），软件通用化（支持Windows、Linux，可随意安装卸载应用） | 硬件高性能（多CPU、大内存、冗余存储），软件专用化（如Linux Server、数据库系统），支持集群扩展 |
> | **性能与资源**          | 性能适中（CPU主频几MHz~几GHz），资源有限（内存几KB~几GB、存储几MB~几百GB） | 性能均衡（CPU主频2~5GHz），资源丰富（内存8~64GB、存储512GB~数TB） | 性能极致（多路CPU、内存128GB~数TB、存储PB级），支持硬件冗余（如双电源、RAID） |
> | **用户交互**            | 多为“无交互”或“极简交互”（如家电通过按键/APP间接控制，工业设备通过专用面板操作） | 强交互（依赖显示器、键盘、鼠标，支持图形化界面） | 无直接用户交互（通过网络远程管理，面向程序/服务调用） |
> | **生命周期**            | 长（5~20年，如汽车电子、工业设备需长期稳定运行，不轻易升级） | 短（3~5年，硬件易迭代，软件需频繁更新） | 中长（5~10年，硬件按需升级，软件需持续维护以保障服务） |
> | **实时性要求**          | 多数有严格实时性（如汽车ECU需毫秒级响应刹车信号，工业控制需微秒级同步） | 无强制实时性（如办公软件延迟1~2秒可接受） | 侧重“吞吐量”而非“实时性”（如云计算服务延迟100ms内可接受） |

#### 计算机系统：硬件+软件

![alt text](image-4.png)

#### 计算机和处理器的推动力及历史

> [!note] “后摩尔时代”
>
> **“后摩尔时代”**指的是传统依靠“缩小晶体管尺寸”提升芯片性能和集成度的路径逐渐逼近物理极限，芯片技术发展从“单一维度迭代”转向“多维度创新”的新阶段，并非摩尔定律完全失效。
>
> 1. 进入“后摩尔时代”的原因
> - **物理极限**：晶体管尺寸缩小到5nm以下时，出现量子隧穿效应，导致漏电和性能不稳定，导线宽度也逼近原子尺度，难以继续缩小。
> - **成本飙升**：先进工艺生产线和研发成本极高，仅少数巨头能承担，性价比降低。
> - **功耗与散热问题**：晶体管密度提升导致热密度急剧上升，散热困难，影响芯片可靠性。
>
> 2. 后摩尔时代的核心特征
> - **不再依赖尺寸缩小**：通过3D立体结构（如3D晶体管、纳米片晶体管）提升密度。
> - **不再依赖单一芯片**：采用多芯片集成（如SoC堆叠、Chiplet技术）提升性能与灵活性。
> - **不再依赖传统硅基材料**：探索氮化镓、碳化硅等新材料，以及碳纳米管、石墨烯等前沿技术，突破物理瓶颈。

- **发展阶段**：
  - 1945 - 1970年，主要是大型计算机（Mainframes）和小型计算机（minicomputers）。
  - 70年代，集成电路技术催生了微型计算机（microcomputer）。
  - 80年代，精简指令集（RISC）处理器开始出现。
  - 2005年以后，多核处理器逐渐发展起来。
- **处理器设计关键技术**：涵盖流水线、指令并行（超标量、VLIW）、数据并行（SIMD）、多核、缓存等，推动了处理器性能提升。

| 技术类型      | 定义与实现方式                                              | 代表架构/产品                | 主要优缺点                  | 适用场景                  |
|---------------|------------------------------------------------------------|-----------------------------|-----------------------------|---------------------------|
| 超标量        | 硬件动态调度，多条指令并行执行（如乱序执行）                | Intel Pentium、ARM Cortex-A | 兼容性强，性能高，硬件复杂  | 通用计算、高性能CPU        |
| VLIW          | 编译器静态打包多指令，处理器并行执行                        | TI TMS320C62XX、Itanium     | 硬件简单，需重编译，代码膨胀| DSP、多媒体、嵌入式        |
| SIMD          | 一条指令并行处理多个数据（如向量、数组）                    | Intel SSE/AVX、ARM NEON     | 吞吐高，需数据对齐          | 多媒体、科学计算、信号处理 |

| 处理器名 | 时间 | 晶体管数 | 速度（MHz） | 关键特点 |
| ---- | ---- | ---- | ---- | ---- |
| 8086 | 1978 | 29K | 5 - 10 | 首款16位英特尔处理器，是IBM PC和DOS的基础，地址空间为1MB |
| 80386 | 1985 | 275K | 16 - 33 | 首款32位英特尔处理器，被称为IA32，增加了“平面寻址”，能运行Unix |
| Pentium 4E | 2004 | 125M | 2800 - 3800 | 首款64位英特尔x86处理器，被称为x86 - 64 |
| Core 2 | 2006 | 291M | 1060 - 3500 | 首款英特尔多核处理器 |
| Core i7 | 2008 | 731M | 1700 - 3900 | 拥有四个核心 |


#### 解决微处理器挑战的可能方向

- **领域专用处理器**：一方面有面向AI应用的GPU及加速器，可助力人工智能相关任务高效运行；另一方面随着技术发展，也会催生其他新应用场景下的专用处理器。
- **新型体系架构关键技术的突破**：包括存算一体的器件、电路及架构，这种架构能优化计算与存储的协同；还有类脑芯片，模仿人脑的工作机制，有望带来全新的计算模式。
- **新型存储器关键技术的突破**：聚焦于高速、高容量的非易失存储器，像RRAM（电阻式随机存取存储器）、MRAM（磁随机存取存储器）、PRAM（相变随机存取存储器）等，这类存储器在性能和存储能力上有更好表现。

### 第二章 微处理器结构

冯·诺依曼计算机结构

我们今天使用的几乎所有电脑、手机、服务器，其最核心的设计思想都源于此。

![alt text](image-17.png)

1. **输入设备 (Input Devices)**

从外部获取信息的设备。在电脑上，键盘、鼠标、麦克风就是输入设备，负责把你的指令和数据告诉计算机。

2. **存储器 (Memory/Storage)**

存放数据和指令的地方。在电脑里，内存（RAM）和硬盘（Hard Drive）就是存储器，程序和需要处理的文件都放在里面。

3. **微处理器 (Microprocessor / CPU)**：计算机的大脑，它由两个关键部分组成：

  - **运算器 (Arithmetic Logic Unit, ALU)**
    执行算术和逻辑运算。所有实际的数据处理都在这里完成。

  - **控制器 (Control Unit, CU)**
    指挥和协调计算机各部分工作。计算机中所有部件的行动，都是由控制器来发号施令的。

4. **输出设备 (Output Devices)**

将处理结果展示给用户。在电脑上，显示器、打印机、音响就是输出设备，它们把计算机处理完的结果（文字、图像、声音）展示给你。

**采用二进制**：计算机内部的所有信息，无论是指令还是数据，最终都会被转换成由0和1组成的二进制码。简单、稳定，适合用电子元器件来实现。

**“存储程序”思想 (Stored-Program Concept)**：在冯·诺依曼之前，计算机的程序是固化在硬件里的（通过插拔无数根电线来改变程序，就像**ENIAC**）。而冯·诺依曼提出，程序（指令）本身也应该像数据一样，被存储在存储器中。计算机可以按顺序自动地从存储器中取出指令并执行。这个思想的伟大之处在于，它实现了<span style="background:rgba(163, 218, 252, 0.55)">软件和硬件的分离</span>。我们想让计算机做不同的事，不再需要改造硬件，只需要加载不同的软件（程序）就行了。

### 第三章 80x86 指令系统

#### 80x86 寻址方式
##### 背景——存储器的体系结构

现实中不存在完美的单一存储器。因此，设计师们设计了一个 **“金字塔”** 式的 **分层体系结构 (Hierarchy)**，用系统，用“较低成本”的硬件“欺骗”CPU，让它以为自己拥有了近乎“理想”的存储器。

###### “存储金字塔”的层级（从上到下，从快到慢）

**第1层：CPU 寄存器 (CPU Registers)**

- **特点**：在CPU芯片内部，与CPU的计算单元“零距离”。访问速度**最快**（1个时钟周期），但数量极少（几十个），<span style="background:rgba(186, 173, 239, 0.55)">成本极高</span>。`AX`, `EBX` 这些就是寄存器。

**第2层：高速缓冲存储器 (Cache)**

- **特点**：焊在CPU芯片上或紧贴CPU的超高速小内存。它存在的唯一目的就是**缓解CPU（超快）和主存（很慢）之间的速度矛盾**。

**第3层：主存储器 (Main Memory / RAM)**

- **特点**：我们常说的“内存条”（如16GB RAM）。CPU执行的所有程序和数据，都必须**先从硬盘加载到这里**才能运行。<span style="background:rgba(186, 173, 239, 0.55)">它的速度远慢于Cache，但容量远大于Cache</span>。

**第4层：辅助存储器 (Auxiliary Storage)**

- **特点**：我们常说的“移动硬盘“。容量巨大、价格便宜、断电不丢失数据。但速度最慢。

###### 体系的运作：局部性原理 (Principle of Locality)

这个金字塔体系能高效工作的核心，是利用了程序的“惰性”，即**局部性原理**：

1. **时间局部性**：刚用过的数据，很可能马上还要再用一次。（比如循环变量 `i`）。
    
2. **空间局部性**：刚用过的数据，它旁边的数据，很可能马上也要被用。（比如数组`a[1]`用完，很可能就用`a[2]`）。

**工作流程**：

1. CPU需要数据，先问 **Cache** 有没有
    
2. **Cache命中 (Hit)**：若Cache里正好有。CPU立刻拿到数据，皆大欢喜。（电脑第二次打开同一个软件会快很多）。
    
3. **Cache未命中 (Miss)**：Cache里没有。CPU**被迫停工（Stall）**，等待Cache去问**主存**要。主存把数据（连同一小块邻近的数据）一起交给Cache，Cache再交给CPU。

##### 指令的格式

一条指令，就是程序员能对CPU下达的、最基本的一个命令。

指令的两大组成部分：

- **操作码 (Opcode) / 助记符 (Mnemonic)**
    
    - **作用**：指令的 **“动词 (Verb)”** ，规定了CPU **“做什么”** 。
        
    - **例**：`MOV` (传送)、`ADD` (加法)、`SUB` (减法)、`JMP` (跳转)。
        
    - **助记符**：`MOV` 是给人看的“助记符”。但CPU真正看的是机器码，比如`B8`。
        
- **操作数 (Operands)**
    
    - **作用**：指令的 **“宾语 (Object)”** ，规定了CPU **“对谁做”**、**“用什么做”** 。
        
    - **例**：在`MOV AX, 1234H`中，`AX` 和 `1234H` 就是两个操作数。
        
    - **说明**：不同指令的操作数个数不同。`INC AX` (让`AX`自增1) 只有一个操作数；`MOV AX, 1234H` 有两个；`RET` (函数返回) 可以没有操作数。

> [!note] 以`MOV`指令作为典型案例：
> - **格式**：`MOV 目的操作数, 源操作数`
> - **功能**：将**“源”**的数据，**复制**一份，传送到**“目的”**。
> - **注**：这是x86架构的Intel语法，**目标在左，源在右**。这就像一个赋值语句：`目的 = 源`。
##### 寻址方式

- **立即寻址 (Immediate)**：操作数包含在代码中。
 
**数据就在“指令”上写着**。比如命令是：“拿`1234`这个数字”。数据`1234`本身就是命令的一部分。

- **寄存器寻址 (Register)**：操作数存放在寄存器中。

**数据就在CPU的“口袋”里**（`AX`, `EBX`等寄存器）。这是CPU最喜欢的方式，因为拿取速度**最快**，零延迟。

- **存储器寻址 (Memory)**：操作数存放在存储器中。

**数据在“外面的大仓库”里**（内存）。CPU需要拿着“地址”（仓库货架号）跑过去取，这会花费一些时间（涉及Cache, 主存）。

- **I/O端口寻址 (I/O Port)**：操作数存放在I/O端口中。

**数据在“公司大门口的快递站”**。数据来自外部设备（如键盘、网卡）。CPU需要执行特殊指令（如 `IN`, `OUT`）去签收。

> [!danger] 
> 寻址方式是**针对操作数**而言的。
> 
> - 在一条指令 `MOV AX, BX` 中：
>     
>     - **目的操作数** `AX`，使用的是“寄存器寻址”。
>         
>     - **源操作数** `BX`，使用的也是“寄存器寻址”。
>         
> - 在一条指令 `MOV AX, [1234H]` 中：
>     
>     - **目的操作数** `AX`，使用的是“寄存器寻址”。
>         
>     - **源操作数** `[1234H]`，使用的是“存储器寻址”。
###### 立即寻址

**定义**：操作数（数据）就**紧跟在操作码后面**，作为指令机器码的一部分，存放在内存的**代码段**中。

>[!note] 案例分析（`MOV AX, 1234H`）
>**“完整指令”** 被分为两部分：
>
>1. **操作码 (Opcode)**：`MOV AX, ...` 的机器语言。CPU一读到这个码，就知道接下来是一个16位的数据，我要把它装进`AX`。
>
>2. **立即数 (Immediate Data)**：就是`1234H`。

> [!warning] 小端序 (Little-Endian) 存储
> 数据部分被拆成了 `34H(低8位)` 和 `12H(高8位)`。在内存中存放时，`34H`（低位字节）被存放在**较低的地址**，`12H`（高位字节）被存放在**较高的地址**。 Intel x86 架构的“小端序”规定，多字节数据的“小头”（低位字节）要存放在“小地址”（低地址）。

> [!note] 案例分析（`MOV AL, 12H`）
> 
> 这是一个8位操作。操作码会告诉CPU："接下来是一个8位的数据，把它装进`AL`"。
> 内存中就是 `[Opcode] [12H]`。

> [!note] 案例分析（`MOV AX, 12H`）
> 
> 源操作数 `12H` 是8位的，但目的寄存器 `AX` 是16位的。CPU在执行时，会自动进行 **"零扩展" (Zero Extension)** 。它会将 `12H` 装入 `AL` (低8位)，同时**自动用 `00H` 填充 `AH` (高8位)**。因此执行后 `AX` 的值是 `0012H`。

> [!note] 案例分析（MOV EAX, 12345678H）：从16位 (8086) 走向32位 (80386)
> 
> 1. 它会有一个**操作码 (Opcode)**，告诉CPU："这是一条`MOV` 32位立即数到`EAX`的指令"。
>     
> 2. 这4个字节的数据 `12345678H` 会以**小端序 (Little-Endian)** 的方式存放在内存中。
>     
> 3. 在内存中的实际字节顺序是：`[Opcode] [78H] [56H] [34H] [12H]`。

> [!tip] 拓展（C3-1）：立即寻址的重要性
> 
> 1. **编译器（Compiler）** 的最爱：当在 **C++** 或 **Java** 中写 `int i = 10;` 或者 `for (int j = 0; j < 100; j++)`，这里的 `10` 、 `0` 、 `100` 几乎100%会被编译器编译成使用**立即寻址**的指令（如 `MOV EAX, 10`）。
> 2. **立即数的性能**：数据随着指令**一起被取回来了**（大概率已在CPU的指令缓存`L1-Cache`中）。CPU不需要再跑一趟去访问数据缓存（`L1-Data-Cache`）或主存，避免了潜在的流水线停顿（`Stall`）。
> 3. **RISC-V** 中的立即数：在 **ARM** 和 **RISC-V** 中，由于RISC指令长度固定（如32位），它们没有空间放下超长的立即数。因此，它们会设计特殊的指令（如 `LUI` - Load Upper Immediate），专门用来分两步拼装一个大的立即数，或者将立即数的设计与指令格式巧妙地融合在一起，这是现代CPU设计的一个核心挑战。

###### 寄存器寻址

操作数就存放在寄存器中，所有的高级语言**编译器**（如C++, Java, Python的）其核心优化任务之一就是 **“寄存器分配”** 。编译器会拼尽全力分析你的代码，把最常用、最核心的变量（比如`for`循环中的变量`i`）尽可能地长时间 **“钉死”在寄存器里** ，这也是为什么优化后的代码会快得多。

> [!note] 案例分析
> 
> - **例1: `MOV AX, BX`**
>    
> 经典的16位传送。将`BX`寄存器中全部16位的内容，完整地复制到`AX`寄存器中。
> 
> - **例2: `MOV EAX, EBX`**
> 
> 这是80386时代的32位传送。原理完全相同，但数据"水管"的直径从16位变成了32位。
> 
> - **例3: `MOV CL, CH`**
> 
> CPU内部操作的**高精度**。`CH`是`CX`寄存器的高8位（`C` register `High` byte），`CL`是`CX`的低8位（`C` register `Low` byte）。这条指令是把高8位的数据，复制到低8位。这在进行字节（Byte）级别的复杂数据拼装时非常有用。

###### 存储器寻址

程序的大部分数据，如变量、数组、对象等，都存放在**内存**里。

**偏移地址的计算：16位机 (如8086)**

我们知道8086的物理地址是 `段地址:偏移地址`。“存储器寻址”要干的所有事情，就是**计算出这个“偏移地址”**。这个计算出来的“偏移地址”，在术语中就叫做**有效地址 (EA)**，即：

`偏移地址（16位）=有效地址（EA） = 基址 (Base) + 变址 (Index) + 位移量 (Displacement)`

- **基址 (Base)**：`BX` 或 `BP`
	- **`BX`** (Base Register) 通常用于指向**数据段 (`DS`)** 中的数据。
	- **`BP`** (Base Pointer) 专门用于指向**堆栈段 (`SS`)** 中的数据。

- **变址 (Index)**：`SI` 或 `DI`
    - **作用**：在“基础货架号”上提供一个“动态的偏移”。
    - **`SI`** (Source Index) / **`DI`** (Destination Index) 适合用来做“索引”，比如数组的遍历。
        
- **位移量 (Displacement)**：一个8位或16位的常数（如 `8` 或 `1234H`）。
    - **作用**：提供一个“固定的偏移”。

**偏移地址的计算：32位机 (如80386)**

`EA = 基址 + (变址 * 比例因子) + 位移量`

- **更灵活的基址/变址**：**任何**通用寄存器 (`EAX`, `EBX`, `ECX`...) 都可以充当“基址”或“变址”。这给了编译器极大的自由度。
- **更大的位移量**：可以使用32位的常数，轻松访问大型数据结构。
- **比例因子 (Scale Factor: 1, 2, 4, 8)**：这是**最重要的升级**。允许CPU在计算EA时，自动将“变址”寄存器的值乘以1、2、4或8。

> [!tip] 拓展（C3-2）: 为什么"比例因子"是革命性的？
> 
> 这个功能是**为高级语言（如C/C++）量身定做的**。假设你在C++中定义了一个整数数组： `int my_array[10];`:
> 
> 在32位系统中，一个 `int` 占**4个字节**。
> 
> - `my_array[0]` 在内存地址 `Addr`
> - `my_array[1] A` 在内存地址 `Addr + 4`
> - `my_array[2]` 在内存地址 `Addr + 8`
> 
> 现在，你想执行这行代码：`x = my_array[i];`，CPU必须计算出 `my_array[i]` 的地址，公式是：`Addr + i * 4`。
> 
> **在8086上 (没有比例因子)**：CPU必须分多步执行，非常慢：
> ```asm
> MOV CX, i      ; 1. 把 i 放到一个寄存器
> SAL CX, 2      ; 2. 把 CX 乘以 4 (左移2位)
> MOV BX, Addr   ; 3. 把数组基地址放到 BX
> ADD BX, CX     ; 4. 计算出 EA
> MOV AX, [BX]   ; 5. 终于取到了数据！
> ```
> **在80386上 (有比例因子)**：硬件一步到位！
> ```asm
> MOV EAX, i                    ; 1. 把 i 放到 EAX (作为变址)
> MOV EBX, [Addr + EAX * 4]     ; 2. 搞定！
> ```
> 这个`比例因子`（1, 2, 4, 8）就是为了直接在硬件层面支持 `char` (1字节), `short` (2字节), `int/float` (4字节), `double/long long` (8字节) 这些**C语言基本数据类型的数组访问**。这是硬件辅助软件性能起飞的绝佳范例。

**“默认段规则”**：

1. 如果`EA`计算中**使用了 `BP`, `EBP` 或 `ESP`**，CPU就**自动**认为是在**堆栈段 (SS)** 里找数据。
    
2. 否则（比如用了`BX`, `EAX`, `SI`等），CPU就**自动**认为是在**数据段 (DS)** 里找数据。

**为什么有这个规则？—— 为了函数和局部变量**
 
- **数据段 (DS)** 用来存放**全局变量 (Global Variables)**。
- **堆栈段 (SS)** 用来存放**函数的参数 (Parameters)** 和**局部变量 (Local Variables)**。

当你调用一个C函数 `my_func(int a)` 时：
    
1. 参数 `a` 被压入堆栈。
2. 函数开始执行，`EBP` 寄存器会指向这块堆栈区域的“基底”（称为栈帧）。
3. 你的参数 `a` 就在 `[EBP + 8]` 的位置。
4. 你的局部变量 `int x` 就在 `[EBP - 4]` 的位置。

当编译器编译 `x = a;` 这句代码时，它会生成： `MOV EAX, [EBP+8] ; CPU自动使用SS段, 取回参数a` ，`MOV [EBP-4], EAX ; CPU自动使用SS段, 存入局部变量x`

这个规则让编译器可以清晰地将**全局数据（DS）** 和**函数内数据（SS）** 隔离开来。

>[!danger] 消失的段地址
>段地址几乎从来不会直接写在指令语句中。它就是根据计算有效地址(`EA`)的寄存器来自动“默认匹配”的。
>
>CPU内部有一套“默认规则表”，规定了在计算`EA`时使用了什么寄存器，就自动匹配哪个段寄存器
>
>**段超越 (Segment Override)**：
>
>汇编语言提供了一个“例外”机制，叫做**段超越前缀 (Segment Override Prefix)**。您可以在指令前面手动指定一个段寄存器，来**临时“覆盖”**掉默认规则。
>- 默认情况 (用DS)：`MOV AX, [BX] ` $\implies$  物理地址 = `(DS) * 16 + (BX)`
>- 使用“段超越” (强制用ES)：`MOV AX, ES:[BX]` $\implies$  物理地址 = `(ES) * 16 + (BX)`

1. **直接寻址**：程序直接通过操作数的地址来访问该操作数。

在 `EA = 基址 + 变址 + 位移量` 这个公式中，让 **基址=0, 变址=0**。因此，`EA = 位移量`。这个“位移量”（偏移地址）是一个**常数**（如`1234H`），被**直接编码在指令的机器码中**。

> [!note] 案例：默认寻址 (`MOV AX, [1234H]`)
> 
> ![alt text](image-26.png)
> 
> - **第1步：计算16位有效地址 (EA)**
>     
>     - 寻址方式是"直接寻址"。`EA = 0 + 0 + 1234H`
> 
> - **第2步：计算20位物理地址**
>     
>     - CPU检查指令，发现没有`BP`寄存器参与运算。按照**默认规则**，CPU自动选择**数据段寄存器 (DS，设 `(DS) = 5000H`)** 。
>     - `物理地址 = (DS) * 16 + EA = 5000H * 10H + 1234H = 51234H`

- CPU跑到`51234H`这个物理地址去取数据。
- **小端序(Little-Endian)再次登场**：
    
    - CPU在**低地址`51234H`** 读到了`89H`，将其放入`AX`的**低8位(AL)**。
    - CPU在**高地址`51235H`** 读到了`67H`，将其放入`AX`的**高8位(AH)**。
        
- **运行结果**：`AX`寄存器中最终的值是 `6789H`。

> [!tip] 拓展（C3-3）：直接寻址的工业应用
>
> "直接寻址"在现代编程中用于访问**全局变量 (Global Variables)** 和 **静态变量 (Static Variables)**。
>
> 当编译器（如C++编译器）编译程序时，它会把所有全局变量统一安放在数据段（.data段）的某个固定位置。比如，`int globalVar;` 可能会被固定分配在 `DS:[1234H]`。因此，程序中所有对 `globalVar` 的访问，都会被编译成 `MOV [1234H], ...` 这样的"直接寻址"指令。

2. **寄存器间接寻址**：操作数的偏移量（EA）存放在一个寄存器中。

在 `EA = 基址 + 变址 + 位移量` 公式中，我们只使用“基址”或“变址”。

> [!note] 案例分析 (MOV AX, [BX])
>
> 假设 `(DS) = 5000H`，并且我们**提前已经把 `1234H` 这个值存入了 `BX` 寄存器**中（比如通过 `MOV BX, 1234H`）。
>
> ![alt text](image-27.png)
>
> CPU执行 `MOV AX, [BX]`：
>
> - **第1步：计算16位有效地址 (EA)**
>     
>     - 寻址方式是"寄存器间接寻址"。CPU去读取 `BX` 寄存器的内容。
>     - `EA = (BX) = 1234H`
>
> - **第2步：计算20位物理地址**
>     
>     - CPU检查指令，发现使用的是 `BX` 寄存器（而不是`BP`）。按照**默认规则**，CPU自动选择**数据段寄存器 (DS)**。
>         
>     - `物理地址 = (DS) * 16 + EA = 50000H + 1234H = 51234H`
> - **结果**：CPU同样去`51234H`取到了`6789H`放入`AX`。

3. **寄存器相对寻址**：`EA（偏移量）= 基址/变址寄存器 + 位移量`。

> [!note] 案例分析：MOV AX, [BX+1000H]
>
> ![alt text](image-28.png)
>
> - **第1步：计算16位有效地址 (EA)**
>     
>     - `EA = (BX) + 1000H = 1234H + 1000H = 2234H`
>
> - **第2步：计算20位物理地址**
>     
>     - CPU检查到EA的计算使用了`BX`（而不是`BP`）。按照**默认规则**，CPU自动选择**数据段 (DS)**。
>     - `物理地址 = (DS) * 16 + EA = 50000H + 2234H = 52234H`

> [!tip] 拓展（C3-4）:
>
> "寄存器相对寻址"是高级语言（如C/C++）实现 `struct` (结构体) 或 `class` (类) 访问的硬件基石。
>
> 假设你用C++定义了一个结构体：
> ```cpp
> struct Employee {
>     int id;       // 偏移量 0
>     char name[8]; // 偏移量 4
>     long salary;  // 偏移量 12
> };
> ```
> 当你创建一个指向这个结构体的指针 `Employee* p;` 时，编译器可能会把这个指针 `p` 的值（即`Employee`对象的起始地址）存放在 `EBX` 寄存器中。
>
> 执行 `long s = p->salary;` 这句代码时，编译器如何找到`salary`？
>
> `salary` 存放在结构体**起始地址偏移12个字节**的地方。编译器会生成这样的汇编指令： `MOV EAX, [EBX + 12]`

4. **基址变址寻址**：`EA = (BX 或 BP) + (SI 或 DI)`

![alt text](image-29.png)
5. **相对基址变址寻址**：